{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75801c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\George\\Desktop\\ds_projects\\project_ds_salaries\\ds_salaries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5b0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the size of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that company locations are in 2 letters format so we want to get the whole country name for later use\n",
    "country_codes = pd.read_excel(r'C:\\Users\\George\\Desktop\\ds_projects\\project_ds_salaries\\country_codes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8088a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df, country_codes[['country', 'country_code_2']], how='left', left_on='company_location', right_on='country_code_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f12117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After the merge we have 13 columns\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualise again\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have no use for the country_code_2 column\n",
    "new_df.drop(['country_code_2'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21caec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see all the available currencies in our dataset\n",
    "new_df['salary_currency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As of 06/26/2022\n",
    "def salary_to_usd(x, y):\n",
    "    if x == 'CAD':\n",
    "        return y * 0.78\n",
    "    elif x == 'CNY':\n",
    "        return y * 0.15\n",
    "    elif x == 'EUR':\n",
    "        return y * 1.06       \n",
    "    elif x == 'GBP':\n",
    "        return y * 1.23\n",
    "    elif x == 'HUF':\n",
    "        return y * 0.0026\n",
    "    elif x == 'INR':\n",
    "        return y * 0.013\n",
    "    elif x == 'JPY':\n",
    "        return y * 0.0074\n",
    "    elif x == 'MXN':\n",
    "        return y * 0.05\n",
    "    elif x == 'DKK':\n",
    "        return y * 0.14\n",
    "    elif x == 'PLN':\n",
    "        return y * 0.23\n",
    "    elif x == 'SGD':\n",
    "        return y * 0.72\n",
    "    elif x == 'CLP':\n",
    "        return y * 0.0011\n",
    "    elif x == 'BRL':\n",
    "        return y * 0.19\n",
    "    elif x == 'TRY':\n",
    "        return y * 0.059\n",
    "    elif x == 'AUD':\n",
    "        return y * 0.69\n",
    "    elif x == 'CHF':\n",
    "        return y * 1.04\n",
    "    elif x =='USD':\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de46a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get the count of occurences for the countries in our dataset\n",
    "occurences = new_df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b666b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to have an \"accurate\" picture of the salaries per country so we exclude countries that have an occurence less than 10\n",
    "countries = occurences[occurences > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63249889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bck = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove rows that refer to countries that appear less than 10 times\n",
    "df = new_df.loc[new_df['country'].isin(list(countries.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f827ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see after the above pre-processing how many rows are left in our data. We drop 83 (607 - 524) rows.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to see the average salary in USD per country\n",
    "df[['country', 'salary_in_usd']].groupby(['country']).agg('mean').sort_values(by=['salary_in_usd'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743286eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As well as how many salaries per country we have available in our dataset\n",
    "df[['country', 'salary_in_usd']].groupby(['country']).agg('count').sort_values(by=['salary_in_usd'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b02013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to take it a step further and compare the salaries per country in our data with the GDP per capita for each of the countries\n",
    "\n",
    "#Datase from https://worldpopulationreview.com/country-rankings/median-income-by-country\n",
    "import swifter\n",
    "average_wage = pd.read_csv(r'C:\\Users\\George\\Desktop\\ds_projects\\project_ds_salaries\\yearly_income_per_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_wage.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19140f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_salaries_per_country_in_dataset = df[['country', 'salary_in_usd']].groupby(['country']).agg('mean').sort_values(by=['salary_in_usd'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_salaries_per_country_in_dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b956f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We replace the country name for US so that when we merge with average_wage dataframe we can bring data\n",
    "mean_salaries_per_country_in_dataset['country'] = mean_salaries_per_country_in_dataset['country'].replace(['United States of America (the)'], 'United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the name for United Kingdom as well\n",
    "mean_salaries_per_country_in_dataset['country'] = mean_salaries_per_country_in_dataset['country'].replace(['United Kingdom of Great Britain and Northern Ireland (the)'], 'United Kingdom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_salaries_per_country_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d89217",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ds_salaries_vs_mean_salaries_overall = pd.merge(mean_salaries_per_country_in_dataset, average_wage, how='left', on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec489ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ds_salaries_vs_mean_salaries_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1519a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a column that is the difference between salaries in our dataset and GDP per capita\n",
    "mean_ds_salaries_vs_mean_salaries_overall['difference'] = mean_ds_salaries_vs_mean_salaries_overall['salary_in_usd'] - mean_ds_salaries_vs_mean_salaries_overall['gdpPerCapitaPPP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we print the dataframe sorted by the column we created that shows us in which country data scientists are getting paid better relative to their peers\n",
    "mean_ds_salaries_vs_mean_salaries_overall[['country', 'salary_in_usd', 'gdpPerCapitaPPP', 'difference']].sort_values(by=['difference'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seems that in US data scientists are getting better. However, we should also think of outliers that their existence could have skewed our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the min salary in USD per country ?\n",
    "df[['country', 'salary_in_usd']].groupby(['country']).agg('min').sort_values(by=['salary_in_usd'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the maximum salary in USD per country ?\n",
    "df[['country', 'salary_in_usd']].groupby(['country']).agg('max').sort_values(by=['salary_in_usd'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce630d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We observe that the difference between the min and max salary in US particularly is too big. So further analysis is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create the scatter plots of salaries in USD per country that will give us a clearer picture for outliers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20,30))\n",
    "\n",
    "countries = list(df['country'].unique())\n",
    "\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(len(countries)):\n",
    "    if i % 3 == 0 and i != 0:        \n",
    "        k += 1\n",
    "        j = 0    \n",
    "    x = [i for i in range(df.loc[df['country']==countries[i]].shape[0])]\n",
    "    y = list(df.loc[df['country']==countries[i], 'salary_in_usd'])    \n",
    "    axs[k, j].scatter(x, y)\n",
    "    title = 'Available Salaries in USD'\n",
    "    axs[k, j].set_title(title)\n",
    "    axs[k, j].set_xlabel(countries[i])\n",
    "    j += 1\n",
    "    \n",
    "for ax in axs.flat:\n",
    "    ax.set(ylabel='Salaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdbee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indeed we observe that for most countries there exist some outliers. In US most salaries are concentrated in the range (50K - 200K) but there exist a salary of 600K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's continue the visual exploration of our dataset, since it will help us understand better our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "\n",
    "df = df_bck.copy() #Our initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first plot the salaries in USD that exist in our data per year. We see an uplift of the median salary per year, probably following inflation.\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "work_year = list(df['work_year'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(work_year)):\n",
    "    data.append(df.loc[df['work_year']==work_year[i], 'salary_in_usd'])\n",
    "\n",
    "axs.boxplot(data)\n",
    "axs.set_title('Salaries in USD per work_year')\n",
    "axs.set_ylabel('Salary')\n",
    "plt.xticks([1, 2, 3], ['2020', '2021', '2022'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034401bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#However there is an important consideration when it comes to plotting vs each other. We need to have around the same amount of data per category so that our comparisons are fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b759274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how much data we have per work year. We see that for 2022 we have a lot more data\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "work_year = list(df['work_year'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(work_year)):               \n",
    "    data.append(df.loc[df['work_year']==work_year[i]].shape[0])\n",
    "\n",
    "axs.bar(work_year,data)\n",
    "axs.set_title('Number of employees per work_year')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the salaries in USD per experience level. As expected we see an increase in the median salary as experience level progresses\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "experience_level = ['EN', 'MI', 'SE', 'EX']\n",
    "\n",
    "data = []\n",
    "for i in range(len(experience_level)):    \n",
    "    data.append(df.loc[df['experience_level']==experience_level[i], 'salary_in_usd'])\n",
    "\n",
    "axs.boxplot(data)\n",
    "axs.set_title('Salaries in USD per experience_level')\n",
    "axs.set_ylabel('Salary')\n",
    "plt.xticks([1, 2, 3, 4], ['EN', 'MI', 'SE', 'EX'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5891ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how much data we have per experience level. We see that for entry level and executive experience level we have considerably less data\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "experience_level = list(df['experience_level'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(experience_level)):               \n",
    "    data.append(df.loc[df['experience_level']==experience_level[i]].shape[0])\n",
    "\n",
    "axs.bar(experience_level,data)\n",
    "axs.set_title('Number of employees per experience_level')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot salaries in USD per employment type. We see that for Contract agreements the range fluctuates much more than for the rest employment types\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "employment_type = list(df['employment_type'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(employment_type)):       \n",
    "    data.append(df.loc[df['employment_type']==employment_type[i], 'salary_in_usd'])\n",
    "\n",
    "axs.boxplot(data)\n",
    "axs.set_title('Salaries in USD per employment_type')\n",
    "axs.set_ylabel('Salary')\n",
    "plt.xticks([1, 2, 3, 4], ['FT', 'CT', 'PT', 'FL'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how much data we have per employment type. As expected for full time working we have a lot more\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "employment_type = list(df['employment_type'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(employment_type)):               \n",
    "    data.append(df.loc[df['employment_type']==employment_type[i]].shape[0])\n",
    "\n",
    "axs.bar(employment_type,data)\n",
    "axs.set_title('Number of employees per employment_type')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us also plot salaries in USD vs ratio of remote working. Seems that hybrid working employers are paid less compared to their colleagues\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "remote_ratio = list(df['remote_ratio'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(remote_ratio)):           \n",
    "    data.append(df.loc[df['remote_ratio']==remote_ratio[i], 'salary_in_usd'])\n",
    "\n",
    "axs.boxplot(data)\n",
    "axs.set_title('Salaries in USD per remote_ratio')\n",
    "axs.set_ylabel('Salary')\n",
    "plt.xticks([1, 2, 3], ['0', '50', '100'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how much data we have per remote working option\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "remote_ratio = list(df['remote_ratio'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(remote_ratio)):               \n",
    "    data.append(df.loc[df['remote_ratio']==remote_ratio[i]].shape[0])\n",
    "\n",
    "axs.bar(remote_ratio,data)\n",
    "axs.set_title('Number of employees per remote_ratio')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally let us plot the salary in USD vs the company size. Medium sized companies seem to be paying less\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "company_size = list(df['company_size'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(company_size)):               \n",
    "    data.append(df.loc[df['company_size']==company_size[i], 'salary_in_usd'])\n",
    "\n",
    "axs.boxplot(data)\n",
    "axs.set_title('Salaries in USD per company_size')\n",
    "axs.set_ylabel('Salary')\n",
    "plt.xticks([1, 2, 3], ['L', 'M', 'S'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how much data we have per company size. Most people in our dataset work for medium sized companies\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "company_size = list(df['company_size'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(company_size)):               \n",
    "    data.append(df.loc[df['company_size']==company_size[i]].shape[0])\n",
    "\n",
    "axs.bar(company_size,data)\n",
    "axs.set_title('Number of employees per company_size')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0335af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how much data we have per company location. Most of the companies are based in the US\n",
    "fig, axs = plt.subplots(figsize=(10,20))\n",
    "\n",
    "company_location = list(df['company_location'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(company_location)):               \n",
    "    data.append(df.loc[df['company_location']==company_location[i]].shape[0])\n",
    "\n",
    "axs.barh(company_location,data)\n",
    "axs.set_title('Number of employees per company_location')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how much data we have for employee residences. Most of our employees live in US\n",
    "fig, axs = plt.subplots(figsize=(10,20))\n",
    "\n",
    "employee_residence = list(df['employee_residence'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(employee_residence)):               \n",
    "    data.append(df.loc[df['employee_residence']==employee_residence[i]].shape[0])\n",
    "\n",
    "axs.barh(employee_residence,data)\n",
    "axs.set_title('Number of employees per employee_residence')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13e5eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finally lets see which job roles are most represented in our data. We see that data scientists followed by data engineer are the two most common job titles\n",
    "fig, axs = plt.subplots(figsize=(10,30))\n",
    "\n",
    "job_title = list(df['job_title'].unique())\n",
    "\n",
    "data = []\n",
    "for i in range(len(job_title)):               \n",
    "    data.append(df.loc[df['job_title']==job_title[i]].shape[0])\n",
    "\n",
    "axs.barh(job_title,data)\n",
    "axs.set_title('Number of employees per job_title')\n",
    "axs.set_ylabel('Employees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would like to build a model that is able to predict the salary that an employer will receive. Howeve we are limited by the amount of available data. Therefore, we are going to generate some data to aid us. We are going to use the CTGAN Model as it was proposed by Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan Veeramachaneni in their paper titled \"Modeling Tabular data using Conditional GAN\" that was accepted at NeurIPS, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7571f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['salary', 'salary_currency'], inplace=True, axis=1) #We are removing these column since we have no use of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4971db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remote_ratio'] = df['remote_ratio'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cb81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['work_year'] = df['work_year'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "spearman_cors = {}\n",
    "\n",
    "cols = list(df.columns)\n",
    "cols.remove('salary_in_usd')\n",
    "for i in range(len(cols)-1):\n",
    "    for j in range(i+1, len(cols)): \n",
    "        spearman_cors[cols[i] + \"__\" + cols[j]] = stats.spearmanr(df[cols[i]], df[cols[j]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3895dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_cors_df = pd.DataFrame(spearman_cors.items(), columns=['Pair', 'Spearman_Correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min correlation pair')\n",
    "spearman_cors_df.loc[spearman_cors_df['Spearman_Correlation']==spearman_cors_df['Spearman_Correlation'].min(), ['Pair', 'Spearman_Correlation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max correlation pair')\n",
    "spearman_cors_df.loc[spearman_cors_df['Spearman_Correlation']==spearman_cors_df['Spearman_Correlation'].max(), ['Pair', 'Spearman_Correlation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd006969",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_cors_df.sort_values(by=['Spearman_Correlation'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "spearman_cors = {}\n",
    "\n",
    "cols = list(df.columns)\n",
    "cols.remove('salary_in_usd')\n",
    "for i in range(len(cols)):\n",
    "    spearman_cors[cols[i] + \"__salary_in_usd\"] = stats.spearmanr(df[cols[i]], df['salary_in_usd'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f977f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_cors_df = pd.DataFrame(spearman_cors.items(), columns=['Pair', 'Spearman_Correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min correlation pair')\n",
    "spearman_cors_df.loc[spearman_cors_df['Spearman_Correlation']==spearman_cors_df['Spearman_Correlation'].min(), ['Pair', 'Spearman_Correlation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max correlation pair')\n",
    "spearman_cors_df.loc[spearman_cors_df['Spearman_Correlation']==spearman_cors_df['Spearman_Correlation'].max(), ['Pair', 'Spearman_Correlation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_cors_df.sort_values(by=['Spearman_Correlation'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e52f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['company_location'], inplace=True, axis=1) #We are removing these column as they provoke high collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0c0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_outliers = list(df['salary_in_usd'].sort_values(ascending=False).index)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a4b46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252    600000\n",
       "97     450000\n",
       "33     450000\n",
       "157    423000\n",
       "225    416000\n",
       "63     412000\n",
       "523    405000\n",
       "519    380000\n",
       "25     325000\n",
       "482    324000\n",
       "Name: salary_in_usd, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_in_usd'].iloc[high_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0243ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_outliers = list(df['salary_in_usd'].sort_values(ascending=False).index)[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c952bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127    9466\n",
       "196    9272\n",
       "15     8000\n",
       "21     6072\n",
       "50     6072\n",
       "213    5882\n",
       "18     5707\n",
       "179    5679\n",
       "77     5409\n",
       "238    4000\n",
       "185    4000\n",
       "176    2859\n",
       "Name: salary_in_usd, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_in_usd'].iloc[low_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7389d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = [ind for ind in list(df.index) if ind not in high_outliers and ind not in low_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8676056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55b874b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_year             object\n",
       "experience_level      object\n",
       "employment_type       object\n",
       "job_title             object\n",
       "salary_in_usd          int64\n",
       "employee_residence    object\n",
       "remote_ratio          object\n",
       "company_size          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59509ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d4265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a094bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CTGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d436f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\George\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:286: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "C:\\Users\\George\\AppData\\Roaming\\Python\\Python39\\site-packages\\ctgan\\data_transformer.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].to_numpy().flatten()\n"
     ]
    }
   ],
   "source": [
    "model.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61734375",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = model.sample(num_rows=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f83995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum salary in synthetic data 600000\n",
      "Maximum salary in initial data 600000 \n",
      "\n",
      "Minimum salary in synthetic data 2859\n",
      "Minimum salary in initial data 2859\n"
     ]
    }
   ],
   "source": [
    "#Let's run some validation on the newly created dataset so that we can ensure everything is as expected\n",
    "\n",
    "print('Maximum salary in synthetic data', new_data['salary_in_usd'].max())\n",
    "print('Maximum salary in initial data', df['salary_in_usd'].max(), '\\n')\n",
    "\n",
    "print('Minimum salary in synthetic data', new_data['salary_in_usd'].min())\n",
    "print('Minimum salary in initial data', df['salary_in_usd'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f780f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to check also if there are unexpected values in any of the other columns\n",
    "cols = list(new_data.columns)\n",
    "cols.remove('salary_in_usd')\n",
    "for col in cols:\n",
    "    if set(list(df[col].unique())) != set(list(new_data[col].unique())):\n",
    "        print(col, ' column differs')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a4b06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8976bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nice there are no surpises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15247389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets evaluate now the quality of our generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112941fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We firstly use a likelihood metric that fits a model on our initial data and then computes the likelihood that the generated data have come from the same distribution\n",
    "\n",
    "from sdv.metrics.tabular import BNLikelihood, BNLogLikelihood, GMLogLikelihood\n",
    "\n",
    "raw_score = GMLogLikelihood.compute(df.fillna(0), new_data.fillna(0))\n",
    "GMLogLikelihood.normalize(raw_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b65616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For reference if we use the same dataset and pass it to the evalaution method we get back a 0.02 value\n",
    "raw_score = GMLogLikelihood.compute(new_data.fillna(0), new_data.fillna(0))\n",
    "GMLogLikelihood.normalize(raw_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e893e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also use a dtetection metric that fits a model to distinguish whether a row has come from the synthetic data or the initial data\n",
    "\n",
    "from sdv.metrics.tabular import SVCDetection\n",
    "\n",
    "SVCDetection.compute(df, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb211a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above evaluation we can see that although not perfect the quality of the data is at least acceptable and for lack of better alternative we are going to use them to fit a ML model to predict salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8df6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to use only the newly created data for training and we are going to use the real data to assess our model's performance\n",
    "training_data = new_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.concat([new_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e52a624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data.copy()\n",
    "y = X['salary_in_usd']\n",
    "X.drop(['salary_in_usd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df2243dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_year             0\n",
       "experience_level      0\n",
       "employment_type       0\n",
       "job_title             0\n",
       "employee_residence    0\n",
       "remote_ratio          0\n",
       "company_size          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c9e1970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28993, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170d380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.copy()\n",
    "y_test = X_test['salary_in_usd']\n",
    "X_test.drop(['salary_in_usd'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f5425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "051ae859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of our features are categorical hence pre-processing is needed before we can pass them over to a regression model. For ordinal features we are going to use label encoding, for nominal features with low cardinality we use one-hot encoding and finally for high cardinallity nominal features we use binary encoding\n",
    "import category_encoders as ce\n",
    "\n",
    "experience_level_encoder = ce.OrdinalEncoder(cols=['experience_level'],return_df=True, mapping=[{'col':'experience_level', 'mapping':{'SE':0,'MI':1,'EN':2,'EX':3}}])\n",
    "X['experience_level_encoded'] = experience_level_encoder.fit_transform(X['experience_level'])\n",
    "X_test['experience_level_encoded'] = experience_level_encoder.transform(X_test['experience_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['experience_level_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42573eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_ratio_encoder = ce.OrdinalEncoder(cols=['remote_ratio'],return_df=True, mapping=[{'col':'remote_ratio', 'mapping':{'0':0,'50':1,'100':2}}])\n",
    "X['remote_ratio_encoded'] = remote_ratio_encoder.fit_transform(X['remote_ratio'])\n",
    "X_test['remote_ratio_encoded'] = remote_ratio_encoder.transform(X_test['remote_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898389bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['remote_ratio_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['remote_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac4ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_size_encoder = ce.OrdinalEncoder(cols=['company_size'],return_df=True, mapping=[{'col':'company_size', 'mapping':{'S':0,'M':1,'L':2}}])\n",
    "X['company_size_encoded'] = company_size_encoder.fit_transform(X['company_size'])\n",
    "X_test['company_size_encoded'] = company_size_encoder.transform(X_test['company_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['company_size_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ae784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea8b70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_year_encoder = ce.OneHotEncoder(cols='work_year', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "work_year_encoded = work_year_encoder.fit_transform(X['work_year'])\n",
    "work_year_encoded_test = work_year_encoder.transform(X_test['work_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "879640c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_type_encoder = ce.OneHotEncoder(cols='employment_type', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "employment_type_encoded = employment_type_encoder.fit_transform(X['employment_type'])\n",
    "employment_type_encoded_test = employment_type_encoder.transform(X_test['employment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_type_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5e03036",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_encoder= ce.BinaryEncoder(cols=['job_title'],return_df=True)\n",
    "job_title_encoded = job_title_encoder.fit_transform(X['job_title']) \n",
    "job_title_encoded_test = job_title_encoder.transform(X_test['job_title']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37761f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb66da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_residence_encoder= ce.BinaryEncoder(cols=['employee_residence'],return_df=True)\n",
    "employee_residence_encoded = employee_residence_encoder.fit_transform(X['employee_residence']) \n",
    "employee_residence_encoded_test = employee_residence_encoder.transform(X_test['employee_residence']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f68834",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_residence_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07772acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_location_encoder= ce.BinaryEncoder(cols=['company_location'],return_df=True)\n",
    "company_location_encoded = company_location_encoder.fit_transform(X['company_location']) \n",
    "company_location_encoded_test = company_location_encoder.transform(X_test['company_location']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d58952",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_location_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a035735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28993, 3)\n",
      "(28993,)\n",
      "(28993, 4)\n",
      "(28993, 6)\n",
      "(28993, 6)\n",
      "(28993,)\n",
      "(28993,)\n"
     ]
    }
   ],
   "source": [
    "print(work_year_encoded.shape)\n",
    "print(X['experience_level_encoded'].shape)\n",
    "print(employment_type_encoded.shape)\n",
    "print(job_title_encoded.shape)\n",
    "print(employee_residence_encoded.shape)\n",
    "print(X['remote_ratio'].shape)\n",
    "#print(company_location_encoded.shape)\n",
    "print(X['company_size_encoded'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad7b6cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607, 3)\n",
      "(607,)\n",
      "(607, 4)\n",
      "(607, 6)\n",
      "(607, 6)\n",
      "(607,)\n",
      "(607,)\n"
     ]
    }
   ],
   "source": [
    "print(work_year_encoded_test.shape)\n",
    "print(X_test['experience_level_encoded'].shape)\n",
    "print(employment_type_encoded_test.shape)\n",
    "print(job_title_encoded_test.shape)\n",
    "print(employee_residence_encoded_test.shape)\n",
    "print(X_test['remote_ratio'].shape)\n",
    "#print(company_location_encoded_test.shape)\n",
    "print(X_test['company_size_encoded'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f882321",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transformed_df = pd.concat([work_year_encoded, X['experience_level_encoded'], employment_type_encoded, job_title_encoded, X['remote_ratio_encoded'], employee_residence_encoded, X['company_size_encoded']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55e2d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transformed_df_test = pd.concat([work_year_encoded_test, X_test['experience_level_encoded'], employment_type_encoded_test, job_title_encoded_test, X_test['remote_ratio_encoded'], employee_residence_encoded_test, X_test['company_size_encoded']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f15f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28993, 22)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d58c2a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 22)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transformed_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "187a4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regr = RandomForestRegressor(n_estimators=1000, n_jobs=-1, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ca89653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lnr_regr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cda7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87185eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca4718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da28b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transformed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bca88944",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_regr.fit(new_transformed_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d3f57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr_model = lnr_regr.fit(new_transformed_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed14893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80374.70856714177"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, rf_model.predict(new_transformed_df_test))** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab40989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77140.69054605727"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, lnr_model.predict(new_transformed_df_test))** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5097f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rem = y_test.iloc[to_keep]\n",
    "new_transformed_df_test_rem = new_transformed_df_test.iloc[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f59487a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63331.495093579106"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test_rem, lnr_model.predict(new_transformed_df_test_rem))** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d8f9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = abs(y_test - lnr_model.predict(new_transformed_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d4a6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2cda048",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a914281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112297.86985172982"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_in_usd'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77272586",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i in range(607)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c037b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = [ind for ind in indices if ind not in list(diff.index)[:22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519aaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_rem = y_test.iloc[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transformed_df_test_rem = new_transformed_df_test.iloc[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab34e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "experience_level_encoder = ce.OneHotEncoder(cols='experience_level', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "experience_level_encoded = experience_level_encoder.fit_transform(X['experience_level'])\n",
    "experience_level_encoded_test = experience_level_encoder.transform(X_test['experience_level'])\n",
    "\n",
    "remote_ratio_encoder = ce.OneHotEncoder(cols='remote_ratio', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "remote_ratio_encoded = remote_ratio_encoder.fit_transform(X['remote_ratio'])\n",
    "remote_ratio_encoded_test = remote_ratio_encoder.transform(X_test['remote_ratio'])\n",
    "\n",
    "company_size_encoder = ce.OneHotEncoder(cols='company_size', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "company_size_encoded = company_size_encoder.fit_transform(X['company_size'])\n",
    "company_size_encoded_test = company_size_encoder.transform(X_test['company_size'])\n",
    "\n",
    "work_year_encoder = ce.OneHotEncoder(cols='work_year', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "work_year_encoded = work_year_encoder.fit_transform(X['work_year'])\n",
    "work_year_encoded_test = work_year_encoder.transform(X_test['work_year'])\n",
    "\n",
    "employment_type_encoder = ce.OneHotEncoder(cols='employment_type', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "employment_type_encoded = employment_type_encoder.fit_transform(X['employment_type'])\n",
    "employment_type_encoded_test = employment_type_encoder.transform(X_test['employment_type'])\n",
    "\n",
    "job_title_encoder = ce.OneHotEncoder(cols='job_title', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "job_title_encoded = job_title_encoder.fit_transform(X['job_title'])\n",
    "job_title_encoded_test = job_title_encoder.transform(X_test['job_title'])\n",
    "\n",
    "employee_residence_encoder = ce.OneHotEncoder(cols='employee_residence', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "employee_residence_encoded = employee_residence_encoder.fit_transform(X['employee_residence'])\n",
    "employee_residence_encoded_test = employee_residence_encoder.transform(X_test['employee_residence'])\n",
    "\n",
    "# company_location_encoder = ce.OneHotEncoder(cols='company_location', handle_unknown='return_nan', return_df=True, use_cat_names=True)\n",
    "# company_location_encoded = company_location_encoder.fit_transform(X['company_location'])\n",
    "# company_location_encoded_test = company_location_encoder.transform(X_test['company_location'])\n",
    "\n",
    "new_transformed_df = pd.concat([experience_level_encoded, remote_ratio_encoded, company_size_encoded, work_year_encoded, employment_type_encoded,job_title_encoded,employee_residence_encoded],axis=1 )\n",
    "new_transformed_df_test = pd.concat([experience_level_encoded_test, remote_ratio_encoded_test, company_size_encoded_test, work_year_encoded_test, employment_type_encoded_test,job_title_encoded_test,employee_residence_encoded_test],axis=1 )\n",
    "print(new_transformed_df.shape)\n",
    "print(new_transformed_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64173c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_regr.fit(new_transformed_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb68a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr_model = lnr_regr.fit(new_transformed_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, rf_model.predict(new_transformed_df_test))** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, lnr_model.predict(new_transformed_df_test))** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7162f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test_rem, lnr_model.predict(new_transformed_df_test_rem))** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c89627",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[list(diff.index)[:30]].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71123932",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[list(diff.index)[:30]].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[list(diff.index)[:30]]['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8773b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[list(diff.index)[:30]]['remote_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831457b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[list(diff.index)[:30]]['experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lnr_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lnr_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc70421",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regr_new = RandomForestRegressor(n_estimators=500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_new = rf_regr_new.fit(new_transformed_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2decad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, rf_model_new.predict(new_transformed_df_test))** (1/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
